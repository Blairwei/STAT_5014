---
title: "HW2_Wei_Yanran_Problems 4-7"
author: "Yanran Wei"
date: "September 12, 2017"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 4
Version control can assist in:
1). **Bcakup.** If any server dies, and these system were collaborating via Version Control Systems, any of the repositories can be copied back up to the server to restore it. Every clone is a full backup of all the data.
2). **Revision History.** Version Control Systems have a simple databse that keeps all the changes to files under revision control.
3). **Collaboration.** People need to collaborate with developers on other systems. Version Control Systems can solve this problem. These systems have a single server that contains all the versioned files, and people can check out files from that central place.

## Problem 5

```{r}
library(dplyr)
library(tidyr)
library(readr)
```

### Part A. Sensory Data
```{r}
 url<-"http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/Sensory.dat"
    Sensory_raw<-read.table(url, header=F, skip=1, fill=T, stringsAsFactors = F)
    Sensory_tidy<-Sensory_raw[-1,]
    Sensory_tidy_a<-filter(.data = Sensory_tidy,V1 %in% 1:10) %>%
                    rename(Item=V1,V1=V2,V2=V3,V3=V4,V4=V5,V5=V6)
    Sensory_tidy_b<-filter(.data = Sensory_tidy,!(V1 %in% 1:10)) %>%
                    mutate(Item=rep(as.character(1:10),each=2)) %>%
                    mutate(V1=as.numeric(V1)) %>%
                    select(c(Item,V1:V5))
    Sensory_tidy<-bind_rows(Sensory_tidy_a,Sensory_tidy_b)
    colnames(Sensory_tidy)<-c("Item",paste("Person",1:5,sep="_"))
    Sensory_tidy<-Sensory_tidy %>%  
        gather(Person,value,Person_1:Person_5) %>%  
        mutate(Person = gsub("Person_","",Person)) %>%
        arrange(Item)
```

```{r}
knitr::kable(summary(Sensory_tidy), caption="Sensory data summary")
```

### Part B. Long Jump data
```{r}
url<-"http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/LongJumpData.dat"
    LongJump_raw<-read.table(url, header=F, skip=1, fill=T, stringsAsFactors = F)
    colnames(LongJump_raw)<-rep(c("V1","V2"),4)
    LongJump_tidy<-rbind(LongJump_raw[,1:2],LongJump_raw[,3:4],
                             LongJump_raw[,5:6],LongJump_raw[,7:8])
    LongJump_tidy<-LongJump_tidy %>%  
        filter(!(is.na(V1))) %>%
        mutate(YearCode=V1, Year=V1+1900, dist=V2) %>%
        select(-V1,-V2)
```

```{r}
knitr::kable(summary(LongJump_tidy), caption="Long Jump data summary")
```

### Part C. Brain vs Body data
```{r}
url<-"http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/BrainandBodyWeight.dat"
    BrainBody_raw<-read.table(url, header=F, skip=1, fill=T, stringsAsFactors = F)
    colnames(BrainBody_raw)<-rep(c("Brain","Body"),3)
    BrainBody_tidy<-rbind(BrainBody_raw[,1:2],BrainBody_raw[,3:4],
                             BrainBody_raw[,5:6])
    BrainBody_tidy<-BrainBody_tidy %>%  
        filter(!(is.na(Brain))) 
```

```{r}
knitr::kable(summary(BrainBody_tidy), caption="Brain/Body weight data summary")
```

### Part D. Tomato data
```{r}
url<-"http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/tomato.dat"
    Tomato_raw<-read.table(url, header=F, skip=2, fill=T, stringsAsFactors = F, comment.char = "")
    Tomato_tidy<-Tomato_raw %>%  
        separate(V2,into=paste("C10000",1:3,sep="_"),sep=",",remove=T, extra="merge") %>%
        separate(V3,into=paste("C20000",1:3,sep="_"),sep=",",remove=T, extra="merge") %>%
        separate(V4,into=paste("C30000",1:3,sep="_"),sep=",",remove=T, extra="merge") %>%
        mutate(C10000_3=gsub(",","",C10000_3)) %>%
        gather(Clone,value,C10000_1:C30000_3) %>%
        mutate(Variety=V1, Clone=gsub("C","",Clone)) %>%
        mutate(Variety=gsub("\\\\#"," ",Variety)) %>%
        separate(Clone,into = c("Clone","Replicate")) %>%
        select(-V1,Variety,Clone,value) %>%
        arrange(Variety) 
```

```{r}
knitr::kable(summary(Tomato_tidy), caption="Tomato data summary")
```

### Problem 6

```{r}
library(swirl)
# Path to data
.datapath <- file.path(path.package('swirl'), 'Courses',
                      'R_Programming_E', 'Looking_at_Data',
                      'plant-data.txt')
# Read in data
plants <- read.csv(.datapath, strip.white=TRUE, na.strings="")

# Remove annoying columns
.cols2rm <- c('Accepted.Symbol', 'Synonym.Symbol')
plants <- plants[, !(names(plants) %in% .cols2rm)]

# Make names pretty
names(plants) <- c('Scientific_Name', 'Duration', 'Active_Growth_Period',
                   'Foliage_Color', 'pH_Min', 'pH_Max',
                   'Precip_Min', 'Precip_Max',
                   'Shade_Tolerance', 'Temp_Min_F')

# Delete rows with NA value of Foliage_Color, pH_Min, pH_Max
plantsN<-plants[apply(plants,1,function(x)!any(is.na(x))),,drop=F] 

# Select columns of Foliage_Color, pH_Min, pH_Max 
plantsS<-select(plantsN,Foliage_Color,pH_Min,pH_Max)

# Linear Regression between Foliage_Color and pH_Median 
plantsS<-plantsS %>%
mutate(pH_Median=(pH_Min+pH_Max)/2,Color=as.numeric(Foliage_Color))
lm<-lm(formula=Color~pH_Median,data=plantsS)
knitr::kable(summary(lm)$coefficients)
aov1<-aov(Color~pH_Median,data=plantsS)
summary(aov1)
```

## Problem 7
### a. Load databasets
```{r}
# Load dataset into R
library(data.table)
setwd("C:/Users/Echo/Downloads")
    Car_Gebreken_raw <- read.csv("Open_Data_RDW__Gebreken.csv",stringsAsFactors = F, nrows=200, header=T,quote = '"')
    Car_Geconstat_raw <- read.csv("Open_Data_RDW__Geconstateerde_Gebreken.csv", stringsAsFactors = F, nrows=200, header=T)
    Car_Person_raw <- read.csv("Personenauto_basisdata.csv",stringsAsFactors = F, nrows=200, header=T)
    
    Car_Gebreken_raw.colclass <- sapply(Car_Gebreken_raw,class)
    Car_Geconstat_raw.colclass <- sapply(Car_Geconstat_raw,class)
    Car_Person_raw.colclass <- sapply(Car_Person_raw,class)
    
    print("Gebreken")
    print(Car_Gebreken_raw.colclass)

    print("Geconstat")
    print(Car_Geconstat_raw.colclass)

    print("Personen")
    print(Car_Person_raw.colclass)
```

### b. Merge three tables
```{r}
colnames(Car_Gebreken_raw)[1]<-'identification'
colnames(Car_Geconstat_raw)[5]<-'identification'
merge2<-merge(Car_Geconstat_raw,Car_Person_raw,by="Kenteken",all=TRUE)
merge3<-merge(Car_Gebreken_raw,merge2,by="identification",all=TRUE)
```

### c. Clean the data and remove NA
```{r}
# Took the first 7 columns which is useful to questions and shrink the dataset
mergec<-merge3[1:7]
colnames(mergec)<-c("defect_code","begin_date","end_date","make","model","defect_description","license plate")
# Remove NA
mergec2<-mergec[apply(mergec,1,function(x)!any(is.na(x))),,drop=F] 
```

### d. How many DIFFERENT makes and models of cars
```{r}
Mergedd<-filter(mergec2,end_date>=20170101)
makes <- n_distinct(Mergedd$make)
models <- n_distinct(Mergedd$model)
makes
models
```

### e. 5 most frequent defects and  make/models
```{r}
library(sqldf)
test2<-sqldf("select defect_description,make, count (*) as count from Mergedd group by defect_description ORDER BY count DESC LIMIT 5",row.names=TRUE)
test2
```

### f. Relationship between number of defects and make
```{r}
test3<-sqldf("select make, count (*) as count from Mergedd group by defect_description ORDER BY count DESC",row.names=TRUE)
lm2<-lm(count~make,data=test3)
knitr::kable(summary(lm2)$coefficients)
aov2<-aov(formula = count ~ make, data = test3)
summary(aov2)
```
 
### g. Relationship between number of defects and model
```{r}
test4<-sqldf("select model, count (*) as count from Mergedd group by defect_description ORDER BY count DESC",row.names=TRUE)
lm3<-lm(count~model,data=test4)
knitr::kable(summary(lm3)$coefficients)
aov3<-aov(formula = count ~ model, data = test4)
summary(aov3)
```

### h. this workflow can be more efficient by using more frequent and practila operators. 




